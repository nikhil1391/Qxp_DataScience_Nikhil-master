{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "fh=open(\"dataset.csv\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The delimiter in the csv file is '+' instead of comma. This was done to compromise with the commas in the sentence in the sentence of the dataset used.\n",
    "reader = csv.reader(fh, delimiter='+')\n",
    "\n",
    "# It is the dictionary that has the data : { label(positive/negative) : { word : count of number of occurences of the word } }\n",
    "dataset={}\n",
    "\n",
    "# It is the dictionary that keeps the count of records that are labeled a label l for each label l\n",
    "# That is, { label l : No. of records that are labeled l }\n",
    "no_of_items={}\n",
    "\n",
    "# This is the dictionary that contains the count of the occurences of word under each label\n",
    "# That is, { word : { label l : count of the occurence of word with label l } }\n",
    "feature_set={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence\n",
      "drinking is bad habbit\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "# For each sentence in dataset\n",
    "for row in reader:\n",
    "\t# Initialize the label in the dictionary if not present already\n",
    "\tno_of_items.setdefault(row[1],0)\n",
    "\t# Increase the count of occurence of label by 1 for every occurence\n",
    "\tno_of_items[row[1]]+=1\n",
    "\t# Initialize the dictionary for a label if not present\n",
    "\tdataset.setdefault(row[1],{})\n",
    "\t# Split the sentence with respect to non-characters, and donot split if apostophe is present\n",
    "\tsplit_data=re.split('[^a-zA-Z\\']',row[0])\n",
    "\t# For every word in split data\n",
    "\tfor i in split_data:\n",
    "\t\t# Removing stop words to a small extent by ignoring words with length less than 3\n",
    "\t\tif len(i) > 2:\n",
    "\t\t\t# Initialize the word count in dataset\n",
    "\t\t\tdataset[row[1]].setdefault(i.lower(),0)\n",
    "\t\t\t# Increase the word count on its occurence with label row[1]\n",
    "\t\t\tdataset[row[1]][i.lower()]+=1\n",
    "\t\t\t# Initialze a dictionary for a newly found word in feature set\n",
    "\t\t\tfeature_set.setdefault(i.lower(),{})\n",
    "\t\t\t# If the label was found for the word, for the first time, initialize corresponding count value for word as key\n",
    "\t\t\tfeature_set[i.lower()].setdefault(row[1],0)\n",
    "\t\t\t# Increment the count for the word in that label \n",
    "\t\t\tfeature_set[i.lower()][row[1]]+=1\n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "# To calculate the basic probability of a word for a category\n",
    "def calc_prob(word,category):\n",
    "\n",
    "\tif word not in feature_set or word not in dataset[category]:\n",
    "\t\treturn 0\n",
    "\n",
    "\treturn float(dataset[category][word])/no_of_items[category]\n",
    "\n",
    "\n",
    "# Weighted probability of a word for a category\n",
    "def weighted_prob(word,category):\n",
    "\t# basic probability of a word - calculated by calc_prob\n",
    "\tbasic_prob=calc_prob(word,category)\n",
    "\n",
    "\t# total_no_of_appearances - in all the categories\n",
    "\tif word in feature_set:\n",
    "\t\ttot=sum(feature_set[word].values())\n",
    "\telse:\n",
    "\t\ttot=0\n",
    "\t\t\n",
    "\t# Weighted probability is given by the formula\n",
    "\t# (weight*assumedprobability + total_no_of_appearances*basic_probability)/(total_no_of_appearances+weight)\n",
    "\t# weight by default is taken as 1.0\n",
    "\t# assumed probability is 0.5 here\n",
    "\tweight_prob=((1.0*0.5)+(tot*basic_prob))/(1.0+tot)\n",
    "\treturn weight_prob\n",
    "\n",
    "\n",
    "# To get probability of the test data for the given category\n",
    "def test_prob(test,category):\n",
    "\t# Split the test data\n",
    "\tsplit_data=re.split('[^a-zA-Z][\\'][ ]',test)\n",
    "\t\n",
    "\tdata=[]\n",
    "\tfor i in split_data:\n",
    "\t\tif ' ' in i:\n",
    "\t\t\ti=i.split(' ')\n",
    "\t\t\tfor j in i:\n",
    "\t\t\t\tif j not in data:\n",
    "\t\t\t\t\tdata.append(j.lower())\n",
    "\t\telif len(i) > 2 and i not in data:\n",
    "\t\t\tdata.append(i.lower())\n",
    "\n",
    "\tp=1\n",
    "\tfor i in data:\n",
    "\t\tp*=weighted_prob(i,category)\n",
    "\treturn p\n",
    "\n",
    "# Naive Bayes implementation\n",
    "def naive_bayes(test):\n",
    "\t'''\n",
    "\t\tp(A|B) = p(B|A) * p(A) / p(B)\n",
    "\n",
    "\t\tAssume A - Category\n",
    "\t\t\t   B - Test data\n",
    "\t\t\t   p(A|B) - Category given the Test data\n",
    "\n",
    "\t\tHere ignoring p(B) in the denominator (Since it remains same for every category)\n",
    "\t'''\n",
    "\tresults={}\n",
    "\tfor i in dataset.keys():\n",
    "\t\t# Category Probability\n",
    "\t\t# Number of items in category/total number of items\n",
    "\t\tcat_prob=float(no_of_items[i])/sum(no_of_items.values())\n",
    "\n",
    "\t\t# p(test data | category)\n",
    "\t\ttest_prob1=test_prob(test,i)\n",
    "\n",
    "\t\tresults[i]=test_prob1*cat_prob\n",
    "\n",
    "\treturn results\n",
    "\n",
    "print('Enter the sentence')\n",
    "text=input()\n",
    "result=naive_bayes(text)\n",
    "\n",
    "if result['1'] > result['-1']:\n",
    "\tprint('positive')\n",
    "else:\n",
    "\tprint('negative')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
